{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "review1 = \"This is by far the worst Italian food I have had in Chicago. We ordered basic menuitems, calamari, chicken parm etc. Got burnt greasy calamari and cold disgusting chicken. Had to toss the whole thing. Save your money, menuprices are outrageous. PS the marinara sauce is red not orange.\"\n",
    "review2 = \"A wonderful Italianfood, best Italian restaurant in Chicago. Everything was very good & the prices are quite reasonable. We ordered the grilled calamari, chickenparm, gnocchi marinara, & olive oil cake. We are going back in two weeks & are very excited to try other menu items.\"\n",
    "texts = [review1, review2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = map(lambda x: x.strip(',.&').lower(), text.split())\n",
    "    tokens = list(filter(None, tokens))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'by', 'far', 'the', 'worst', 'italian', 'food', 'i', 'have', 'had', 'in', 'chicago', 'we', 'ordered', 'basic', 'menuitems', 'calamari', 'chicken', 'parm', 'etc', 'got', 'burnt', 'greasy', 'calamari', 'and', 'cold', 'disgusting', 'chicken', 'had', 'to', 'toss', 'the', 'whole', 'thing', 'save', 'your', 'money', 'menuprices', 'are', 'outrageous', 'ps', 'the', 'marinara', 'sauce', 'is', 'red', 'not', 'orange'], ['a', 'wonderful', 'italianfood', 'best', 'italian', 'restaurant', 'in', 'chicago', 'everything', 'was', 'very', 'good', 'the', 'prices', 'are', 'quite', 'reasonable', 'we', 'ordered', 'the', 'grilled', 'calamari', 'chickenparm', 'gnocchi', 'marinara', 'olive', 'oil', 'cake', 'we', 'are', 'going', 'back', 'in', 'two', 'weeks', 'are', 'very', 'excited', 'to', 'try', 'other', 'menu', 'items']]\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts = list(map(tokenize, texts))\n",
    "print(tokenized_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'and'), (1, 'are'), (2, 'basic'), (3, 'burnt'), (4, 'by'), (5, 'calamari'), (6, 'chicago'), (7, 'chicken'), (8, 'cold'), (9, 'disgusting'), (10, 'etc'), (11, 'far'), (12, 'food'), (13, 'got'), (14, 'greasy'), (15, 'had'), (16, 'have'), (17, 'i'), (18, 'in'), (19, 'is'), (20, 'italian'), (21, 'marinara'), (22, 'menuitems'), (23, 'menuprices'), (24, 'money'), (25, 'not'), (26, 'orange'), (27, 'ordered'), (28, 'outrageous'), (29, 'parm'), (30, 'ps'), (31, 'red'), (32, 'sauce'), (33, 'save'), (34, 'the'), (35, 'thing'), (36, 'this'), (37, 'to'), (38, 'toss'), (39, 'we'), (40, 'whole'), (41, 'worst'), (42, 'your'), (43, 'a'), (44, 'back'), (45, 'best'), (46, 'cake'), (47, 'chickenparm'), (48, 'everything'), (49, 'excited'), (50, 'gnocchi'), (51, 'going'), (52, 'good'), (53, 'grilled'), (54, 'italianfood'), (55, 'items'), (56, 'menu'), (57, 'oil'), (58, 'olive'), (59, 'other'), (60, 'prices'), (61, 'quite'), (62, 'reasonable'), (63, 'restaurant'), (64, 'try'), (65, 'two'), (66, 'very'), (67, 'was'), (68, 'weeks'), (69, 'wonderful')]\n"
     ]
    }
   ],
   "source": [
    "mydict = gensim.corpora.Dictionary(tokenized_texts)\n",
    "print(list(mydict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12, 2), (20, 1), (62, 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now convert to bag of words\n",
    "mydict.doc2bow([\"italian\", \"food\", \"food\", \"reasonable\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(12, 0.8944271909999159), (62, 0.4472135954999579)]\n"
     ]
    }
   ],
   "source": [
    "# Now tf-idf\n",
    "tfidf_model = gensim.models.TfidfModel(dictionary=mydict)\n",
    "result = tfidf_model[mydict.doc2bow([\"italian\", \"food\", \"food\", \"reasonable\"])]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unigrams and bigrams from text\n",
    "def uni_and_bigrams(text):\n",
    "    unigrams = tokenize(text)\n",
    "    # concatenate 2 adjacent tokens with a \"_\" in between\n",
    "    bigrams = list(map(lambda x: '_'.join(x), zip(unigrams, unigrams[1:])))\n",
    "    return unigrams + bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'by', 'far', 'the', 'worst', 'italian', 'food', 'i', 'have', 'had', 'in', 'chicago', 'we', 'ordered', 'basic', 'menuitems', 'calamari', 'chicken', 'parm', 'etc', 'got', 'burnt', 'greasy', 'calamari', 'and', 'cold', 'disgusting', 'chicken', 'had', 'to', 'toss', 'the', 'whole', 'thing', 'save', 'your', 'money', 'menuprices', 'are', 'outrageous', 'ps', 'the', 'marinara', 'sauce', 'is', 'red', 'not', 'orange', 'this_is', 'is_by', 'by_far', 'far_the', 'the_worst', 'worst_italian', 'italian_food', 'food_i', 'i_have', 'have_had', 'had_in', 'in_chicago', 'chicago_we', 'we_ordered', 'ordered_basic', 'basic_menuitems', 'menuitems_calamari', 'calamari_chicken', 'chicken_parm', 'parm_etc', 'etc_got', 'got_burnt', 'burnt_greasy', 'greasy_calamari', 'calamari_and', 'and_cold', 'cold_disgusting', 'disgusting_chicken', 'chicken_had', 'had_to', 'to_toss', 'toss_the', 'the_whole', 'whole_thing', 'thing_save', 'save_your', 'your_money', 'money_menuprices', 'menuprices_are', 'are_outrageous', 'outrageous_ps', 'ps_the', 'the_marinara', 'marinara_sauce', 'sauce_is', 'is_red', 'red_not', 'not_orange'], ['a', 'wonderful', 'italianfood', 'best', 'italian', 'restaurant', 'in', 'chicago', 'everything', 'was', 'very', 'good', 'the', 'prices', 'are', 'quite', 'reasonable', 'we', 'ordered', 'the', 'grilled', 'calamari', 'chickenparm', 'gnocchi', 'marinara', 'olive', 'oil', 'cake', 'we', 'are', 'going', 'back', 'in', 'two', 'weeks', 'are', 'very', 'excited', 'to', 'try', 'other', 'menu', 'items', 'a_wonderful', 'wonderful_italianfood', 'italianfood_best', 'best_italian', 'italian_restaurant', 'restaurant_in', 'in_chicago', 'chicago_everything', 'everything_was', 'was_very', 'very_good', 'good_the', 'the_prices', 'prices_are', 'are_quite', 'quite_reasonable', 'reasonable_we', 'we_ordered', 'ordered_the', 'the_grilled', 'grilled_calamari', 'calamari_chickenparm', 'chickenparm_gnocchi', 'gnocchi_marinara', 'marinara_olive', 'olive_oil', 'oil_cake', 'cake_we', 'we_are', 'are_going', 'going_back', 'back_in', 'in_two', 'two_weeks', 'weeks_are', 'are_very', 'very_excited', 'excited_to', 'to_try', 'try_other', 'other_menu', 'menu_items']]\n"
     ]
    }
   ],
   "source": [
    "tokenized_texts = list(map(uni_and_bigrams, texts))\n",
    "print(tokenized_texts) # now text is represented as unigrams AND bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'and'), (1, 'and_cold'), (2, 'are'), (3, 'are_outrageous'), (4, 'basic'), (5, 'basic_menuitems'), (6, 'burnt'), (7, 'burnt_greasy'), (8, 'by'), (9, 'by_far'), (10, 'calamari'), (11, 'calamari_and'), (12, 'calamari_chicken'), (13, 'chicago'), (14, 'chicago_we'), (15, 'chicken'), (16, 'chicken_had'), (17, 'chicken_parm'), (18, 'cold'), (19, 'cold_disgusting'), (20, 'disgusting'), (21, 'disgusting_chicken'), (22, 'etc'), (23, 'etc_got'), (24, 'far'), (25, 'far_the'), (26, 'food'), (27, 'food_i'), (28, 'got'), (29, 'got_burnt'), (30, 'greasy'), (31, 'greasy_calamari'), (32, 'had'), (33, 'had_in'), (34, 'had_to'), (35, 'have'), (36, 'have_had'), (37, 'i'), (38, 'i_have'), (39, 'in'), (40, 'in_chicago'), (41, 'is'), (42, 'is_by'), (43, 'is_red'), (44, 'italian'), (45, 'italian_food'), (46, 'marinara'), (47, 'marinara_sauce'), (48, 'menuitems'), (49, 'menuitems_calamari'), (50, 'menuprices'), (51, 'menuprices_are'), (52, 'money'), (53, 'money_menuprices'), (54, 'not'), (55, 'not_orange'), (56, 'orange'), (57, 'ordered'), (58, 'ordered_basic'), (59, 'outrageous'), (60, 'outrageous_ps'), (61, 'parm'), (62, 'parm_etc'), (63, 'ps'), (64, 'ps_the'), (65, 'red'), (66, 'red_not'), (67, 'sauce'), (68, 'sauce_is'), (69, 'save'), (70, 'save_your'), (71, 'the'), (72, 'the_marinara'), (73, 'the_whole'), (74, 'the_worst'), (75, 'thing'), (76, 'thing_save'), (77, 'this'), (78, 'this_is'), (79, 'to'), (80, 'to_toss'), (81, 'toss'), (82, 'toss_the'), (83, 'we'), (84, 'we_ordered'), (85, 'whole'), (86, 'whole_thing'), (87, 'worst'), (88, 'worst_italian'), (89, 'your'), (90, 'your_money'), (91, 'a'), (92, 'a_wonderful'), (93, 'are_going'), (94, 'are_quite'), (95, 'are_very'), (96, 'back'), (97, 'back_in'), (98, 'best'), (99, 'best_italian'), (100, 'cake'), (101, 'cake_we'), (102, 'calamari_chickenparm'), (103, 'chicago_everything'), (104, 'chickenparm'), (105, 'chickenparm_gnocchi'), (106, 'everything'), (107, 'everything_was'), (108, 'excited'), (109, 'excited_to'), (110, 'gnocchi'), (111, 'gnocchi_marinara'), (112, 'going'), (113, 'going_back'), (114, 'good'), (115, 'good_the'), (116, 'grilled'), (117, 'grilled_calamari'), (118, 'in_two'), (119, 'italian_restaurant'), (120, 'italianfood'), (121, 'italianfood_best'), (122, 'items'), (123, 'marinara_olive'), (124, 'menu'), (125, 'menu_items'), (126, 'oil'), (127, 'oil_cake'), (128, 'olive'), (129, 'olive_oil'), (130, 'ordered_the'), (131, 'other'), (132, 'other_menu'), (133, 'prices'), (134, 'prices_are'), (135, 'quite'), (136, 'quite_reasonable'), (137, 'reasonable'), (138, 'reasonable_we'), (139, 'restaurant'), (140, 'restaurant_in'), (141, 'the_grilled'), (142, 'the_prices'), (143, 'to_try'), (144, 'try'), (145, 'try_other'), (146, 'two'), (147, 'two_weeks'), (148, 'very'), (149, 'very_excited'), (150, 'very_good'), (151, 'was'), (152, 'was_very'), (153, 'we_are'), (154, 'weeks'), (155, 'weeks_are'), (156, 'wonderful'), (157, 'wonderful_italianfood')]\n"
     ]
    }
   ],
   "source": [
    "mydict = gensim.corpora.Dictionary(tokenized_texts)\n",
    "print(list(mydict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_kernel",
   "language": "python",
   "name": "nlp_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
